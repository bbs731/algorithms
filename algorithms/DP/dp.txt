动态规划常常适用于有重叠子问题和最优子结构性质的问题，并且记录所有子问题的结果，因此动态规划方法所耗时间往往远少于朴素解法。

动态规划有自底向上和自顶向下两种解决问题的方式。自顶向下即记忆化递归，自底向上就是递推。

使用动态规划解决的问题有个明显的特点，一旦一个子问题的求解得到结果，以后的计算过程就不会修改它，这样的特点叫做无后效性，求解问题的过程形成了一张有向无环图。动态规划只解决每个子问题一次，具有天然剪枝的功能，从而减少计算量。


OI 的总结， 深刻吗？ https://oi-wiki.org/dp/basic/ 尤其是最后关于 图论DAG的比喻。
基本思路
对于一个能用动态规划解决的问题，一般采用如下思路解决：

a. 将原问题划分为若干 阶段，每个阶段对应若干个子问题，提取这些子问题的特征（称之为 状态）；
b. 寻找每一个状态的可能 决策，或者说是各状态间的相互转移方式（用数学的语言描述就是 状态转移方程）。
c. 按顺序求解每一个阶段的问题。
如果用图论的思想理解，我们建立一个 有向无环图，每个状态对应图上一个节点，决策对应节点间的连边。这样问题就转变为了一个在 DAG 上寻找最长（短）路的问题（参见：DAG 上的 DP）。

https://oi-wiki.org/dp/memo/
与递推相比，记忆化搜索因为不用明确规定访问顺序，在实现难度上有时低于递推，且能比较方便地处理边界情况，这是记忆化搜索的一大优势。但与此同时，记忆化搜索难以使用滚动数组等优化，且由于存在递归，运行效率会低于递推。因此应该视题目选择更适合的实现方式。



自我总结：
动态规则的特点是，有最有子结构。因为解题的过程中会多次出现重叠子问题，("所以解空间不大, 通常是，常数个子问题，能求得更大子问题的解" 这个理解是有问题的， DP 的时间复杂度不低， O(n^2, n^3, O^4) 等等
的情况， 子问题的规模一般情况下也不是常数的， 一般是O(n)个子问题的选择， 最常见的是 df[j]  0 <= j < i  规模是 O(n) 的。 DP的时间复杂度计算= 状态个数 * 单个状态计算需要花费的时间 ）
子问题的解一旦求得，就不会改变。
求解DP的问题的关键，在于，如何利用常数个子问题，求得解，并且还需要考虑，求解的顺序（保证满足小的子问题的解先得到再到大的子问题，再到最终解的过程）




https://leetcode-cn.com/leetbook/read/dynamic-programming-1-plus/xceyqr/
解决动态规划问题的核心：找出子问题及其子问题与原问题的关系

找到了子问题以及子问题与原问题的关系，就可以递归地求解子问题了。但重叠的子问题使得直接递归会有很多重复计算，于是就想到记忆化递归法：若能事先确定子问题的范围就可以建表存储子问题的答案。

动态规划算法中关于最优子结构和重复子问题的理解的关键点：

证明问题的方案中包含一种选择，选择之后留下一个或多个子问题
设计子问题的递归描述方式
证明对原问题的最优解包括了对所有子问题的最优解
证明子问题是重叠的（这一步不是动态规划正确性必需的，但是如果子问题无重叠，则效率与一般递归是相同的）


https://leetcode-cn.com/leetbook/read/dynamic-programming-1-plus/5ouqw2/
用动态规划解决问题的过程有以下几个关键点：状态定义，状态的转移，初始化和边界条件。
状态定义 就是定义子问题，如何表示目标规模的问题和更小规模的问题。例如常见的方法：定义状态 dp[n]，表示规模为 nn 的问题的解，dp[n - 1] 就表示规模为 n - 1n−1 的子问题的解。在实战中 dp[n] 的具体含义需要首先整理清楚再往下做。
状态转移 就是子问题之间的关系，例如定义好状态 dp[n]，此时子问题是 dp[n-1] 等，并且大规模的问题的解依赖小规模问题的解，此时需要知道怎样通过小规模问题的解推出大规模问题的解。这一步就是列状态转移方程的过程。一般的状态转移方程可以写成如下形式


dp[n] = f(dp[i]) 其中 i < n




0-1 背包问题：
https://leetcode.cn/leetbook/read/dynamic-programming-2-plus/5253i5/
https://oi-wiki.org/dp/knapsack/

区间DP：
https://oi-wiki.org/dp/interval/
